{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing Models with Scrybe\n",
    "This notebook builds various (non-deep learning) models including XGB and LGB Regressor. It showcases how Scrybe, with a single line of code, automatically captures detailed information on each model including: \n",
    "* Feature names\n",
    "* Variable importance\n",
    "* Hyperparameters\n",
    "* Metrics\n",
    "* Lineage \n",
    "\n",
    "We are using data from the House Price Prediction challenge for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrybe Installation\n",
    "\n",
    "*Skip if Scrybe package is already installed*\n",
    "\n",
    "The Scrybe Python package is hosted on a private pip server protected by a username and password. As part of the signing up with Scrybe, you should have received a username and password for the package installation. \n",
    "\n",
    "In the following cell, replace `username` and `password` with the provided username and password. \n",
    "\n",
    "----\n",
    "\n",
    "> If incorrect username and password is provided, the command would **wait/hang** asking for a username. In such case, kill the execution from **Kernel &rarr; Interrupt**, fix the username/password and rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --extra-index-url http://username:password@15.206.48.113:80/simple/ --trusted-host 15.206.48.113 --upgrade scrybe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrybe Initialization\n",
    "\n",
    "You need to `import scrybe` at the beginning of your notebook or Python script and initialize it using your access key. You can find the access key on the Scrybe dashboard.\n",
    "\n",
    "> If you are using Scrybe on-premise, change `host_url` to point to your deployment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrybe\n",
    "scrybe.init(project_name=\"Sample Project\", user_access_key='aa0e0c5c-3138-45b8-9db5-1fb51b536836', host_url='3.6.105.91:5001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrybe Labels\n",
    "With Scrybe, you can easily group different categories of models/experiments by using `scrybe.set_label` API. This allows you to specify a string or array of strings which will get appended as tags to all models/plots/etc. which are created in this process. These tags allow you to filter artifacts easily when looking for information on the dashboard. \n",
    "\n",
    "In this tutorial, we will add to labels: a model version string (\"v2\") and an experiment identifier (\"Traditional\"). In the other tutorial, where we build deep learning models, we'll be using the same version string with a different experiment identifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrybe.set_label([\"v2\", \"Traditional\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "You are now fully setup with Scrybe experiment tracking. Beyond this point, Scrybe will automatically: \n",
    "\n",
    "* Capture any models which get trained \n",
    "* Track model predictions and log metrics computed on them\n",
    "* Print a URL for each model which can be shared with your team to view/comment upon. \n",
    "\n",
    "The rest of the notebook is regular model training code. We start by loading pre-transformed train/test datasets into Pandas frame and build following 5 models:\n",
    "\n",
    "* Lasso\n",
    "* RandomForestRegressor\n",
    "* ExtraTreesRegressor\n",
    "* XGBRegressor\n",
    "* LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('https://raw.githubusercontent.com/scrybe-ml/tutorials/master/data/train_set.csv')\n",
    "test_set = pd.read_csv('https://raw.githubusercontent.com/scrybe-ml/tutorials/master/data/test_set.csv')\n",
    "\n",
    "y = train_set['target'].copy()\n",
    "del train_set['target']\n",
    "y_test = test_set['target']\n",
    "del test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "Scrybe dashboard URL for model_obj:Lasso: http://dashboard.scrybe.ml/#/dashboard/projects/61/models/7e502bc2-c39d-4aa3-a586-91b16a89b78b?client_id=true\n",
      "Test set MSE: 0.1306\n",
      "Test set MAE: 0.255\n",
      "Test set R2: 0.8694\n",
      "forest\n",
      "Scrybe dashboard URL for model_obj:RandomForestRegressor: http://dashboard.scrybe.ml/#/dashboard/projects/61/models/86f68f8d-8e06-4d51-8f3a-58a5f2ab26f7?client_id=true\n",
      "Test set MSE: 0.1763\n",
      "Test set MAE: 0.2882\n",
      "Test set R2: 0.8237\n",
      "xtree\n",
      "Scrybe dashboard URL for model_obj:ExtraTreesRegressor: http://dashboard.scrybe.ml/#/dashboard/projects/61/models/010c936d-c4dc-40c8-906a-8d4969db3f7d?client_id=true\n",
      "Test set MSE: 0.2193\n",
      "Test set MAE: 0.3397\n",
      "Test set R2: 0.7807\n",
      "xgb\n",
      "Scrybe dashboard URL for model_obj:XGBRegressor: http://dashboard.scrybe.ml/#/dashboard/projects/61/models/fd4cbd7d-f676-4a04-96a3-919b1c8b48da?client_id=true\n",
      "Test set MSE: 0.3844\n",
      "Test set MAE: 0.4369\n",
      "Test set R2: 0.6156\n",
      "lgb\n",
      "Scrybe dashboard URL for model_obj:LGBMRegressor: http://dashboard.scrybe.ml/#/dashboard/projects/61/models/7f2d7361-db1c-4ecd-abcb-4b9edf0c3f1e?client_id=true\n",
      "Test set MSE: 0.3289\n",
      "Test set MAE: 0.4065\n",
      "Test set R2: 0.6711\n"
     ]
    }
   ],
   "source": [
    "def select_features(df, model_type):\n",
    "    to_drop = [col for col in df.columns if 'NoGrg' in col]  # dropping dummies that are redundant\n",
    "    to_drop += [col for col in df.columns if 'NoBsmt' in col]\n",
    "\n",
    "    if model_type == 'lasso':\n",
    "        to_drop += [col for col in df.columns if 'BsmtExposure' in col]\n",
    "        to_drop += [col for col in df.columns if 'BsmtCond' in col]\n",
    "        to_drop += [col for col in df.columns if 'ExterCond' in col]\n",
    "        to_drop += [col for col in df.columns if 'HouseStyle' in col]\n",
    "        to_drop += [col for col in df.columns if 'LotShape' in col]\n",
    "        to_drop += [col for col in df.columns if 'LotFrontage' in col]\n",
    "        to_drop += [col for col in df.columns if 'GarageYrBlt' in col]\n",
    "        to_drop += [col for col in df.columns if 'GarageType' in col]\n",
    "        to_drop += ['OpenPorchSF', '3SsnPorch']\n",
    "    if model_type == 'forest':\n",
    "        to_drop += [col for col in df.columns if 'BsmtExposure' in col]\n",
    "        to_drop += [col for col in df.columns if 'BsmtCond' in col]\n",
    "        to_drop += [col for col in df.columns if 'ExterCond' in col]\n",
    "        to_drop += ['OpenPorchSF', '3SsnPorch']\n",
    "    if model_type == 'xgb':\n",
    "        to_drop += [col for col in df.columns if 'BsmtExposure' in col]\n",
    "        to_drop += [col for col in df.columns if 'BsmtCond' in col]\n",
    "        to_drop += [col for col in df.columns if 'ExterCond' in col]\n",
    "    if model_type == 'lgb':\n",
    "        to_drop += [col for col in df.columns if 'LotFrontage' in col]\n",
    "        to_drop += [col for col in df.columns if 'HouseStyle' in col]\n",
    "        to_drop += ['MisBsm']\n",
    "\n",
    "    for col in to_drop:\n",
    "        try:\n",
    "            del df[col]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "models = [('lasso', Lasso(alpha=0.01)),\n",
    "          ('forest', RandomForestRegressor(n_estimators=10)),\n",
    "          ('xtree', ExtraTreesRegressor(n_estimators=10)),\n",
    "          ('xgb', xgb.XGBRegressor(n_estimators=10, objective='reg:squarederror')),\n",
    "          ('lgb', lgb.LGBMRegressor(n_estimators=10))]\n",
    "\n",
    "for model in models:\n",
    "    train = train_set.copy()\n",
    "    test = test_set.copy()\n",
    "    print(model[0])\n",
    "\n",
    "    # Feature subselection\n",
    "    train = select_features(df=train, model_type=model[0])\n",
    "    test = select_features(df=test, model_type=model[0])\n",
    "\n",
    "    model_obj = model[1]\n",
    "    model_obj.fit(train, y)\n",
    "    preds = model_obj.predict(test)\n",
    "\n",
    "    print(f'Test set MSE: {round(mean_squared_error(y_test, preds), 4)}')\n",
    "    print(f'Test set MAE: {round(mean_absolute_error(y_test, preds), 4)}')\n",
    "    print(f'Test set R2: {round(r2_score(y_test, preds), 4)}')\n",
    "    if round(mean_squared_error(y_test, preds), 2) <= 0.2:\n",
    "        scrybe.bookmark(obj=model_obj, obj_name=model[0], msg=\"Shortlisted models with RMSE <= 0.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bookmarking Models\n",
    "You might have noticed in the above script, we added the following code snippet in the training loop: \n",
    "\n",
    "```python\n",
    "if round(mean_squared_error(y_test, preds), 2) <= 0.2:\n",
    "   scrybe.bookmark(obj=model_obj, obj_name=model[0], msg=\"Shortlisted models with RMSE <= 0.2\")\n",
    "```\n",
    "        \n",
    "This allows you to programmatically bookmark certain models based on your specific criteria. So when you go back to the Scrybe dashboard, you will be able to easily shortlist these interesting models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Summary\n",
    "The next part of this tutorial uses `GridSearchCV` to tune our `LGBRegressor` model. The purpose of this part is to familiarize you with some features Scrybe provides specifically around hyperparameter search. \n",
    "\n",
    "Scrybe captures all models trained as part of the grid search but displays only the best estimator in the model listing table. When you view the details of the best estimator (by clicking on the displayed URL or using `scrybe.peek` shown below), you will find two useful pieces of information: \n",
    "\n",
    "* Grid search summary plot: A parallel coordinates plot with all modified hyperparams and the tuning metric as axes\n",
    "* A listing of all models trained within the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrybe dashboard URL for best_estimator:LGBMRegressor: http://dashboard.scrybe.ml/#/dashboard/projects/61/models/1c675049-2a95-4aa2-8716-2ea5334af093?client_id=true\n",
      "[Best estimator] Test set MSE: 0.1655\n",
      "[Best estimator] Test set MAE: 0.2861\n",
      "[Best estimator] Test set R2: 0.8345\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lgb__learning_rate': [0.1, 0.2],\n",
    "    'lgb__n_estimators': [5, 10, 20],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lgb.LGBMRegressor(), param_grid=params, cv=2, scoring=\"neg_mean_squared_error\")\n",
    "train = train_set.copy()\n",
    "test = test_set.copy()\n",
    "grid_search.fit(train, y=y)\n",
    "best_estimator = grid_search.best_estimator_\n",
    "preds = best_estimator.predict(test)\n",
    "print(f'[Best estimator] Test set MSE: {round(mean_squared_error(y_test, preds), 4)}')\n",
    "print(f'[Best estimator] Test set MAE: {round(mean_absolute_error(y_test, preds), 4)}')\n",
    "print(f'[Best estimator] Test set R2: {round(r2_score(y_test, preds), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrybe Peek\n",
    "While you can always click on the displayed model URL to see the model details in Scrybe dashboard and share it with your team, you can also simply load the model page right here in the notebook. With this, you can access Scrybe's rich model details right here in the notbeook. You can also share the model with a team member by adding a comment addressing them using \"@\" callouts. They'll be notified and can see the model in full detail on their own time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dashboard.scrybe.ml/#/dashboard/projects/61/models/1c675049-2a95-4aa2-8716-2ea5334af093?client_id=true\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"http://dashboard.scrybe.ml/#/dashboard/projects/61/models/1c675049-2a95-4aa2-8716-2ea5334af093?client_id=true\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13a457080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrybe.peek(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
